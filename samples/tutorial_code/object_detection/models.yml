%YAML 1.0
---
################################################################################
# Object detection models.
################################################################################

# OpenCV's face detection network
opencv_fd:
  load_info:
    url: "https://github.com/opencv/opencv_3rdparty/b2bfc75f6aea5b1f834ff0f0b865a7c18ff1459f/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel"
    sha1: "15aa726b4d46d9f023526d85537db81cbc8dd566"
  model: "opencv_face_detector.caffemodel"
  config: "opencv_face_detector.prototxt"
  config_info:
    url: "https://github.com/dkurt/cvpr2019/raw/d71841dfd36de0161a08547b27df71df1390bbe5/opencv_face_detector.prototxt"
    sha1: "006baf926232df6f6332defb9c24f94bb9f3764e"
  mean: [104, 177, 123]
  scale: 1.0
  width: 300
  height: 300
  rgb: false
  sample: "object_detection"

# YOLO4 object detection family from Darknet (https://github.com/AlexeyAB/darknet)
# YOLO object detection family from Darknet (https://pjreddie.com/darknet/yolo/)
# Might be used for all YOLOv2, TinyYolov2, YOLOv3, YOLOv4 and TinyYolov4
yolo:
  load_info:
    url: "https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights"
    sha1: "0143deb6c46fcc7f74dd35bf3c14edc3784e99ee"
  model: "yolov4.weights"
  config: "yolov4.cfg"
  config_info:
    url: "https://github.com/AlexeyAB/darknet/raw/c0d6b81a78e204c04c9bf4277974e0dadad0c4e2/cfg/yolov4.cfg"
    sha1: "ed0aeace88527af7524c3baf66ca44fbf049b878"
  mean: [0, 0, 0]
  scale: 0.00392
  width: 416
  height: 416
  rgb: true
  classes: "object_detection_classes_yolov4.txt"
  sample: "object_detection"

yolov5n:
  model: "yolov5n.onnx"
  mean: [0, 0, 0]
  scale: 0.00392
  width: 640
  height: 640
  rgb: true
  classes: "object_detection_classes_yolov4.txt"
  sample: "object_detection"

yolov5s:
  model: "yolov5s.onnx"
  mean: [0, 0, 0]
  scale: 0.00392
  width: 640
  height: 640
  rgb: true
  classes: "object_detection_classes_yolov4.txt"
  sample: "object_detection"

yolov8n:
  model: "yolov8n.onnx"
  mean: [0, 0, 0]
  scale: 0.00392
  width: 640
  height: 640
  rgb: true
  classes: "object_detection_classes_yolov4.txt"
  sample: "object_detection"

yolov8s:
  model: "yolov8s.onnx"
  mean: [0, 0, 0]
  scale: 0.00392
  width: 640
  height: 640
  rgb: true
  classes: "object_detection_classes_yolov4.txt"
  sample: "object_detection"

tiny-yolo-voc:
  load_info:
    url: "https://pjreddie.com/media/files/yolov2-tiny-voc.weights"
    sha1: "24b4bd049fc4fa5f5e95f684a8967e65c625dff9"
  model: "tiny-yolo-voc.weights"
  config: "tiny-yolo-voc.cfg"
  config_info:
    url: "https://github.com/AlexeyAB/darknet/raw/e5ab66d7a770c3861cb93e3fca0079d34b5a26d4/cfg/tiny-yolo-voc.cfg"
    sha1: "d26e2408ce4e20136278411760ba904d744fe5b5"
  mean: [0, 0, 0]
  scale: 0.00392
  width: 416
  height: 416
  rgb: true
  classes: "object_detection_classes_pascal_voc.txt"
  sample: "object_detection"

# Caffe implementation of SSD model from https://github.com/amolikvivian/Caffe-SSD-Object-Detection
ssd_caffe:
  load_info:
    url: "https://github.com/amolikvivian/Caffe-SSD-Object-Detection/raw/8c0bad9a9f5b7dd75e0fa75e42cc9d17157fa0b7/Object%20Detection%20Caffe/Caffe/SSD_MobileNet.caffemodel"
    sha1: "994d30a8afaa9e754d17d2373b2d62a7dfbaaf7a"
  model: "SSD_MobileNet.caffemodel"
  config: "SSD_MobileNet.prototxt"
  config_info:
    url: "https://github.com/amolikvivian/Caffe-SSD-Object-Detection/raw/8c0bad9a9f5b7dd75e0fa75e42cc9d17157fa0b7/Object%20Detection%20Caffe/Caffe/SSD_MobileNet_prototxt.txt"
    sha1: "d77c9cf09619470d49b82a9dd18704813a2043cd"
  mean: [127.5, 127.5, 127.5]
  scale: 0.007843
  width: 300
  height: 300
  rgb: false
  classes: "ssd_object_detection_classes_pascal_voc.txt"
  sample: "object_detection"

# TensorFlow implementation of SSD model from https://github.com/tensorflow/models/tree/master/research/object_detection
ssd_tf:
  load_info:
    url: "http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz"
    sha1: "9e4bcdd98f4c6572747679e4ce570de4f03a70e2"
    download_sha: "6157ddb6da55db2da89dd561eceb7f944928e317"
    download_name: "ssd_mobilenet_v1_coco_2017_11_17.tar.gz"
    member: "ssd_mobilenet_v1_coco_2017_11_17/frozen_inference_graph.pb"
  model: "ssd_mobilenet_v1_coco_2017_11_17.pb"
  config: "ssd_mobilenet_v1_coco_2017_11_17.pbtxt"
  config_info:
    url: "https://github.com/tensorflow/models/raw/7025590841588e82f371ef0fef7dd77a8a71efb8/research/object_detection/samples/configs/ssd_mobilenet_v1_coco.config"
    sha1: "19c8c389439e80746859767ba4ee2617b6501dad"
    filename: "ssd_mobilenet_v1_coco.config"
  mean: [0, 0, 0]
  scale: 1.0
  width: 300
  height: 300
  rgb: true
  classes: "object_detection_classes_coco.txt"
  sample: "object_detection"

# TensorFlow implementation of Faster-RCNN model from https://github.com/tensorflow/models/tree/master/research/object_detection
faster_rcnn_tf:
  load_info:
    url: "http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
    sha1: "f2e4bf386b9bb3e25ddfcbbd382c20f417e444f3"
    download_sha: "c710f25e5c6a3ce85fe793d5bf266d581ab1c230"
    download_name: "faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
    member: "faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb"
  model: "faster_rcnn_inception_v2_coco_2018_01_28.pb"
  config: "faster_rcnn_inception_v2_coco_2018_01_28.pbtxt"
  config_info:
    url: "https://github.com/tensorflow/models/raw/7025590841588e82f371ef0fef7dd77a8a71efb8/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config"
    sha1: "4d676eeab3656695c426670bfafe4e22fa7f54f9"
    filename: "faster_rcnn_inception_v2_coco.config"
  mean: [0, 0, 0]
  scale: 1.0
  width: 800
  height: 600
  rgb: true
  classes: "object_detection_classes_yolov4.txt"
  sample: "object_detection"

################################################################################
# Image classification models.
################################################################################

# SqueezeNet v1.1 from https://github.com/DeepScale/SqueezeNet
squeezenet:
  load_info:
    url: "https://raw.githubusercontent.com/DeepScale/SqueezeNet/b5c3f1a23713c8b3fd7b801d229f6b04c64374a5/SqueezeNet_v1.1/squeezenet_v1.1.caffemodel"
    sha1: "3397f026368a45ae236403ccc81cfcbe8ebe1bd0"
  model: "squeezenet_v1.1.caffemodel"
  config: "squeezenet_v1.1.prototxt"
  mean: [0, 0, 0]
  scale: 1.0
  width: 227
  height: 227
  rgb: false
  classes: "classification_classes_ILSVRC2012.txt"
  sample: "classification"

# Googlenet from https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet
googlenet:
  load_info:
    url: "http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel"
    sha1: "405fc5acd08a3bb12de8ee5e23a96bec22f08204"
  model: "bvlc_googlenet.caffemodel"
  config: "bvlc_googlenet.prototxt"
  mean: [104, 117, 123]
  scale: 1.0
  width: 224
  height: 224
  rgb: false
  classes: "classification_classes_ILSVRC2012.txt"
  sample: "classification"

################################################################################
# Semantic segmentation models.
################################################################################

# ENet road scene segmentation network from https://github.com/e-lab/ENet-training
# Works fine for different input sizes.
enet:
  load_info:
    url: "https://www.dropbox.com/s/tdde0mawbi5dugq/Enet-model-best.net?dl=1"
    sha1: "b4123a73bf464b9ebe9cfc4ab9c2d5c72b161315"
  model: "Enet-model-best.net"
  mean: [0, 0, 0]
  scale: 0.00392
  width: 512
  height: 256
  rgb: true
  classes: "enet-classes.txt"
  sample: "segmentation"

fcn8s:
  load_info:
    url: "http://dl.caffe.berkeleyvision.org/fcn8s-heavy-pascal.caffemodel"
    sha1: "c449ea74dd7d83751d1357d6a8c323fcf4038962"
  model: "fcn8s-heavy-pascal.caffemodel"
  config: "fcn8s-heavy-pascal.prototxt"
  mean: [0, 0, 0]
  scale: 1.0
  width: 500
  height: 500
  rgb: false
  sample: "segmentation"
