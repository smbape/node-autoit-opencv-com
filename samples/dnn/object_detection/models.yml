%YAML 1.0
---
################################################################################
# Object detection models.
################################################################################

# OpenCV's face detection network
opencv_fd:
  load_info:
    url: "https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel"
    sha1: "15aa726b4d46d9f023526d85537db81cbc8dd566"
  model: "opencv_face_detector.caffemodel"
  config: "opencv_face_detector.prototxt"
  config_info:
    url: "https://github.com/dkurt/cvpr2019/raw/d71841dfd36de0161a08547b27df71df1390bbe5/opencv_face_detector.prototxt"
    sha1: "006baf926232df6f6332defb9c24f94bb9f3764e"
  mean: [104, 177, 123]
  scale: 1.0
  width: 300
  height: 300
  rgb: false
  sample: "object_detection"

# YOLO4 object detection family from Darknet (https://github.com/AlexeyAB/darknet)
# YOLO object detection family from Darknet (https://pjreddie.com/darknet/yolo/)
# Might be used for all YOLOv2, TinyYolov2, YOLOv3, YOLOv4 and TinyYolov4
yolov4:
  load_info:
    url: "https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights"
    sha1: "0143deb6c46fcc7f74dd35bf3c14edc3784e99ee"
  model: "yolov4.weights"
  config: "yolov4.cfg"
  config_info:
    url: "https://github.com/AlexeyAB/darknet/raw/c0d6b81a78e204c04c9bf4277974e0dadad0c4e2/cfg/yolov4.cfg"
    sha1: "ed0aeace88527af7524c3baf66ca44fbf049b878"
  mean: [0, 0, 0]
  scale: 0.00392156862745098
  width: 416
  height: 416
  rgb: true
  classes: "object_detection_classes_yolo.txt"
  background_label_id: 0
  sample: "object_detection"

yolov4-tiny:
  load_info:
    url: "https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights"
    sha1: "451caaab22fb9831aa1a5ee9b5ba74a35ffa5dcb"
  model: "yolov4-tiny.weights"
  config: "yolov4-tiny.cfg"
  config_info:
    url: "https://github.com/AlexeyAB/darknet/raw/a298f94255a20a3198d80ea512755d9e5dddbf02/cfg/yolov4-tiny.cfg"
    sha1: "b161c2b0984b0c3b466c04b0d6cb3e52f06d93dd"
  mean: [0, 0, 0]
  scale: 0.00392156862745098
  width: 416
  height: 416
  rgb: true
  classes: "object_detection_classes_yolo.txt"
  background_label_id: 0
  sample: "object_detection"

yolov3:
  load_info:
    url: "https://pjreddie.com/media/files/yolov3.weights"
    sha1: "520878f12e97cf820529daea502acca380f1cb8e"
  model: "yolov3.weights"
  config: "yolov3.cfg"
  config_info:
    url: "https://github.com/AlexeyAB/darknet/raw/efcbdb5425f60d80d9633930f007dfe3caae5220/cfg/yolov3.cfg"
    sha1: "82fb8f6be0382a30b6bdbfe0d6a71b4ac6fd7803"
  mean: [0, 0, 0]
  scale: 0.00392156862745098
  width: 416
  height: 416
  rgb: true
  classes: "object_detection_classes_yolo.txt"
  background_label_id: 0
  sample: "object_detection"

tiny-yolo-voc:
  load_info:
    url: "https://pjreddie.com/media/files/yolov2-tiny-voc.weights"
    sha1: "24b4bd049fc4fa5f5e95f684a8967e65c625dff9"
  model: "tiny-yolo-voc.weights"
  config: "tiny-yolo-voc.cfg"
  config_info:
    url: "https://github.com/AlexeyAB/darknet/raw/e5ab66d7a770c3861cb93e3fca0079d34b5a26d4/cfg/tiny-yolo-voc.cfg"
    sha1: "d26e2408ce4e20136278411760ba904d744fe5b5"
  mean: [0, 0, 0]
  scale: 0.00392156862745098
  width: 416
  height: 416
  rgb: true
  classes: "object_detection_classes_pascal_voc.txt"
  background_label_id: 0
  sample: "object_detection"

yolov5n:
  load_info:
    sha1: "c4d4e0bbf94629860d3906c7d1956d89a968028a"
  model: "yolov5n.onnx"
  mean: [0, 0, 0]
  scale: 0.00392156862745098
  width: 640
  height: 640
  rgb: true
  classes: "object_detection_classes_yolo.txt"
  sample: "object_detection"

yolov5s:
  load_info:
    sha1: "f8e5a67668f5242985e7d5d5b2ea9b3eb1789e78"
  model: "yolov5s.onnx"
  mean: [0, 0, 0]
  scale: 0.00392156862745098
  width: 640
  height: 640
  rgb: true
  classes: "object_detection_classes_yolo.txt"
  sample: "object_detection"

yolov6n:
  load_info:
    url: "https://github.com/meituan/YOLOv6/releases/download/0.4.0/yolov6n.pt"
    sha1: "4f1ab60f0e1cddff63877640b46a58f9eee0b671"
    download_sha: "b801d8ab7b229b6bc832f31d998281461ae67889"
  model: "yolov6n.onnx"
  mean: [0, 0, 0]
  scale: 0.00392156862745098
  width: 640
  height: 640
  rgb: true
  classes: "object_detection_classes_yolo.txt"
  sample: "object_detection"

yolov6s:
  load_info:
    url: "https://github.com/meituan/YOLOv6/releases/download/0.4.0/yolov6s.pt"
    sha1: "a1b21d2b693e8385f0e12914f99d044961561ca0"
    download_sha: "a3070399ae18f089b7a218fedb3348a7add8220b"
  model: "yolov6s.onnx"
  mean: [0, 0, 0]
  scale: 0.00392156862745098
  width: 640
  height: 640
  rgb: true
  classes: "object_detection_classes_yolo.txt"
  sample: "object_detection"

yolov7:
  load_info:
    url: "https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
    sha1: "785792acb6cff09d63bcfa02e5ad1298da841d69"
    download_sha: "723b07225efa90d86eb983713b66fd8be82dfb9f"
  model: "yolov7.onnx"
  mean: [0, 0, 0]
  scale: 0.00392156862745098
  width: 640
  height: 640
  rgb: true
  classes: "object_detection_classes_yolo.txt"
  sample: "object_detection"

yolov7-tiny:
  load_info:
    url: "https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt"
    sha1: "f59e94cadae785d7a16c79339512ba2603b8ed16"
    download_sha: "c42311ff54e2a962725d6cac3b66d4b1e04eda2d"
  model: "yolov7-tiny.onnx"
  mean: [0, 0, 0]
  scale: 0.00392156862745098
  width: 640
  height: 640
  rgb: true
  classes: "object_detection_classes_yolo.txt"
  sample: "object_detection"

yolov8n:
  load_info:
    sha1: "2daace95860c754be076b800a9d2b3b7f75caaec"
  model: "yolov8n.onnx"
  mean: [0, 0, 0]
  scale: 0.00392156862745098
  width: 640
  height: 640
  rgb: true
  postprocessing: "yolov8"
  classes: "object_detection_classes_yolo.txt"
  sample: "object_detection"

yolov8s:
  load_info:
    sha1: "6efc1ac15f82053d7a2d602fe89831685a8c949e"
  model: "yolov8s.onnx"
  mean: [0, 0, 0]
  scale: 0.00392156862745098
  width: 640
  height: 640
  rgb: true
  postprocessing: "yolov8"
  classes: "object_detection_classes_yolo.txt"
  sample: "object_detection"

# Caffe implementation of SSD model from https://github.com/amolikvivian/Caffe-SSD-Object-Detection
ssd_caffe:
  load_info:
    url: "https://github.com/amolikvivian/Caffe-SSD-Object-Detection/raw/8c0bad9a9f5b7dd75e0fa75e42cc9d17157fa0b7/Object%20Detection%20Caffe/Caffe/SSD_MobileNet.caffemodel"
    sha1: "994d30a8afaa9e754d17d2373b2d62a7dfbaaf7a"
  model: "SSD_MobileNet.caffemodel"
  config: "SSD_MobileNet.prototxt"
  config_info:
    url: "https://github.com/amolikvivian/Caffe-SSD-Object-Detection/raw/8c0bad9a9f5b7dd75e0fa75e42cc9d17157fa0b7/Object%20Detection%20Caffe/Caffe/SSD_MobileNet_prototxt.txt"
    sha1: "d77c9cf09619470d49b82a9dd18704813a2043cd"
  mean: [127.5, 127.5, 127.5]
  scale: 0.00784313725490196
  width: 300
  height: 300
  rgb: false
  classes: "object_detection_classes_pascal_voc.txt"
  background_label_id: 0
  sample: "object_detection"

# TensorFlow implementation of SSD model from https://github.com/tensorflow/models/tree/master/research/object_detection
ssd_tf:
  load_info:
    url: "http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz"
    sha1: "9e4bcdd98f4c6572747679e4ce570de4f03a70e2"
    download_sha: "6157ddb6da55db2da89dd561eceb7f944928e317"
    download_name: "ssd_mobilenet_v1_coco_2017_11_17.tar.gz"
    member: "ssd_mobilenet_v1_coco_2017_11_17/frozen_inference_graph.pb"
  model: "ssd_mobilenet_v1_coco_2017_11_17.pb"
  config: "ssd_mobilenet_v1_coco_2017_11_17.pbtxt"
  config_info:
    url: "https://github.com/tensorflow/models/raw/7025590841588e82f371ef0fef7dd77a8a71efb8/research/object_detection/samples/configs/ssd_mobilenet_v1_coco.config"
    sha1: "19c8c389439e80746859767ba4ee2617b6501dad"
    filename: "ssd_mobilenet_v1_coco.config"
  mean: [0, 0, 0]
  scale: 1.0
  width: 300
  height: 300
  rgb: true
  classes: "object_detection_classes_coco.txt"
  background_label_id: 0
  sample: "object_detection"

# TensorFlow implementation of Faster-RCNN model from https://github.com/tensorflow/models/tree/master/research/object_detection
faster_rcnn_tf:
  load_info:
    url: "http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
    sha1: "f2e4bf386b9bb3e25ddfcbbd382c20f417e444f3"
    download_sha: "c710f25e5c6a3ce85fe793d5bf266d581ab1c230"
    download_name: "faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
    member: "faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb"
  model: "faster_rcnn_inception_v2_coco_2018_01_28.pb"
  config: "faster_rcnn_inception_v2_coco_2018_01_28.pbtxt"
  config_info:
    url: "https://github.com/tensorflow/models/raw/7025590841588e82f371ef0fef7dd77a8a71efb8/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config"
    sha1: "4d676eeab3656695c426670bfafe4e22fa7f54f9"
    filename: "faster_rcnn_inception_v2_coco.config"
  mean: [0, 0, 0]
  scale: 1.0
  width: 800
  height: 600
  rgb: true
  classes: "object_detection_classes_yolo.txt"
  sample: "object_detection"

################################################################################
# Image classification models.
################################################################################

# SqueezeNet v1.1 from https://github.com/DeepScale/SqueezeNet
squeezenet:
  load_info:
    url: "https://raw.githubusercontent.com/DeepScale/SqueezeNet/b5c3f1a23713c8b3fd7b801d229f6b04c64374a5/SqueezeNet_v1.1/squeezenet_v1.1.caffemodel"
    sha1: "3397f026368a45ae236403ccc81cfcbe8ebe1bd0"
  model: "squeezenet_v1.1.caffemodel"
  config: "squeezenet_v1.1.prototxt"
  mean: [0, 0, 0]
  scale: 1.0
  width: 227
  height: 227
  rgb: false
  classes: "classification_classes_ILSVRC2012.txt"
  sample: "classification"

# Googlenet from https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet
googlenet:
  load_info:
    url: "http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel"
    sha1: "405fc5acd08a3bb12de8ee5e23a96bec22f08204"
  model: "bvlc_googlenet.caffemodel"
  config: "bvlc_googlenet.prototxt"
  mean: [104, 117, 123]
  scale: 1.0
  width: 224
  height: 224
  rgb: false
  classes: "classification_classes_ILSVRC2012.txt"
  sample: "classification"

################################################################################
# Semantic segmentation models.
################################################################################

# ENet road scene segmentation network from https://github.com/e-lab/ENet-training
# Works fine for different input sizes.
enet:
  load_info:
    url: "https://www.dropbox.com/s/tdde0mawbi5dugq/Enet-model-best.net?dl=1"
    sha1: "b4123a73bf464b9ebe9cfc4ab9c2d5c72b161315"
  model: "Enet-model-best.net"
  mean: [0, 0, 0]
  scale: 0.00392156862745098
  width: 512
  height: 256
  rgb: true
  classes: "enet-classes.txt"
  sample: "segmentation"

fcn8s:
  load_info:
    url: "http://dl.caffe.berkeleyvision.org/fcn8s-heavy-pascal.caffemodel"
    sha1: "c449ea74dd7d83751d1357d6a8c323fcf4038962"
  model: "fcn8s-heavy-pascal.caffemodel"
  config: "fcn8s-heavy-pascal.prototxt"
  mean: [0, 0, 0]
  scale: 1.0
  width: 500
  height: 500
  rgb: false
  sample: "segmentation"

fcnresnet101:
  load_info:
    url: "https://github.com/onnx/models/raw/fb8271d5d5d9b90dbb1eb5e8e40f8f580fb248b3/vision/object_detection_segmentation/fcn/model/fcn-resnet101-11.onnx"
    sha1: "e7e76474bf6b73334ab32c4be1374c9e605f5aed"
  model: "fcn-resnet101-11.onnx"
  mean: [103.5, 116.2, 123.6]
  scale: 0.019
  width: 500
  height: 500
  rgb: false
  sample: "segmentation"
